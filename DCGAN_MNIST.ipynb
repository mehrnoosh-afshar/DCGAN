{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvlnPhEVoKG8yBT7/Uwu0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrnoosh-afshar/DCGAN/blob/main/DCGAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75AM3FJdzEMk"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch \n",
        "import torchvision \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "BATCH_SIZE=128\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "NUM_WORKERS=int(os.cpu_count() / 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "lMmUy-59zKPr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y6bB84oawURR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "  def __init__ (self,data_dir='./data',batch_size=BATCH_SIZE,num_workers=NUM_WORKERS):\n",
        "    super().__init__()\n",
        "    self.data_dir = data_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.num_workers = num_workers\n",
        "\n",
        "    self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            ]\n",
        "        )\n",
        "  def prepare(self):\n",
        "        MNIST(self.data_dir, train=True, download=True)\n",
        "        MNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "        # Validation data not strictly necessary for GAN but added for completeness\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            mnist_full = datasets.MNIST(self.data_dir, train=True, transform=self.transform)\n",
        "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
        "\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.mnist_test = datasets.MNIST(self.data_dir, train=False, transform=self.transform)\n",
        "  def train_dataloader(self):\n",
        "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "  def val_dataloader(self):\n",
        "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "\n",
        "      \n"
      ],
      "metadata": {
        "id": "HUIfjyaP0mJ5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detective: fake or no fake -> 1 output [0, 1]\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Simple CNN\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "  \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        # Flatten the tensor so it can be fed into the FC layers\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "xpcSfErl3W8j"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,latent_dim):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(latent_dim, 7*7*64)  # [n, 256, 7, 7]\n",
        "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
        "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
        "        self.conv = nn.Conv2d(16, 1, kernel_size=7)  # [n, 1, 28, 28]\n",
        "  def forward(self, x):\n",
        "        # Pass latent space input into linear layer and reshape\n",
        "        x = self.lin1(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1, 64, 7, 7)  #256\n",
        "        \n",
        "        # Upsample (transposed conv) 16x16 (64 feature maps)\n",
        "        x = self.ct1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Upsample to 34x34 (16 feature maps)\n",
        "        x = self.ct2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Convolution to 28x28 (1 feature map)\n",
        "        return self.conv(x)\n"
      ],
      "metadata": {
        "id": "5NZdZ1k56881"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(pl.LightningModule):\n",
        "  def __init__(self,latent_dim=100,lr=0.002,b1=0.5, b2=0.999, batch_size=128):\n",
        "    super().__init__()\n",
        "\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "    self.generator = Generator(self.hparams.latent_dim)\n",
        "    self.discriminator = Discriminator()\n",
        "\n",
        "    # Random noise for generator \n",
        "    self.validation_z = torch.randn(6,self.hparams.latent_dim) \n",
        "\n",
        "  def forward(self,z):\n",
        "    return self.generator(z)\n",
        "  def adversarial_loss(self,y,y_hat):\n",
        "    return F.binary_cross_entropy(y,y_hat)\n",
        "  def training_step(self,batch,batch_idx,optimizer_idx):\n",
        "     real_img , _ =  batch\n",
        "\n",
        "     # Build random noises \n",
        "     z = torch.randn(real_img.shape[0],self.hparams.latent_dim)\n",
        "     z= z .type_as(real_img)\n",
        "\n",
        "     # Train generator  max log(D(G(Z)))\n",
        "     if optimizer_idx==0:\n",
        "       fake_img = self.forward(z)\n",
        "       y_hat= self.discriminator(fake_img)\n",
        "\n",
        "       # y is real labes all are one \n",
        "       y = torch.ones(real_img.size(0),1)\n",
        "       y = y.type_as(real_img)\n",
        "       g_loss = self.adversarial_loss(y,y_hat)\n",
        "\n",
        "       log_dic ={\"g_loss\" : g_loss}\n",
        "\n",
        "       return {\"loss\":g_loss, \"progress\":log_dic}\n",
        "\n",
        "     # Train Discriminator  max log(D(x))+log(1-D(G(z)))\n",
        "\n",
        "     if optimizer_idx==1:\n",
        "       y_hat_real = self.discriminator(real_img)\n",
        "       y_real= torch.ones(real_img.size(0),1)\n",
        "       y_real = y_real.type_as(real_img)\n",
        "\n",
        "       real_loss = self.adversarial_loss(y_real,y_hat_real)\n",
        "      \n",
        "       y_hat_fake = self.discriminator(self.forward(z).detach())\n",
        "       y_fake= torch.zeros(real_img.size(0),1)\n",
        "       y_fake = y_fake.type_as(real_img)\n",
        "\n",
        "       fake_loss = self.adversarial_loss(y_fake,y_hat_fake)\n",
        "\n",
        "       d_loss = (real_loss+fake_loss)/2\n",
        "       log_dic ={\"d_loss\" : d_loss}\n",
        "\n",
        "       return {\"loss\":d_loss, \"progress\":log_dic}\n",
        "\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "        lr = self.hparams.lr\n",
        "        b1 = self.hparams.b1\n",
        "        b2 = self.hparams.b2\n",
        "\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "        return [opt_g, opt_d], []\n",
        "\n",
        "\n",
        "  def plot_img(self):\n",
        "    z = self.validation_z.type_as(self.generator.lin1.weight)\n",
        "    sample_img = self.forward(z).cpu()\n",
        "    print(\"epoch\")\n",
        "    fig = plt.figure()\n",
        "    for i in range (sample_img.size(0)):\n",
        "      plt.subplot(2,3,i+1)\n",
        "      plt.tight_layout()\n",
        "      plt.imshow(sample_img.detach()[i,0,:,:])\n",
        "    plt.show()\n",
        "\n",
        "def on_epoch_end(self):\n",
        "        # log sampled images\n",
        "        sample_imgs = self.forward(self.validation_z)\n",
        "        grid = torchvision.utils.make_grid(sample_imgs)\n",
        "        self.logger.experiment.add_image(\"generated_images\", grid, self.current_epoch)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N-PiRXKbTLBu"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm= MNISTDataModule(data_dir='content/data')\n",
        "dm.prepare()\n",
        "dm.setup()\n",
        "dm.train_dataloader()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty6opOkJdd4i",
        "outputId": "c7af4cc9-e36c-4ce6-b4ae-34575243ec0f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f223d109510>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =GAN()\n",
        "model.plot_img()"
      ],
      "metadata": {
        "id": "J9FiPDbtiWW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(max_epochs=20, gpus=AVAIL_GPUS)\n",
        "trainer.fit(model,dm)"
      ],
      "metadata": {
        "id": "XNNwVPUolMa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.on_epoch_end()"
      ],
      "metadata": {
        "id": "vaEVYU0h2maI"
      },
      "execution_count": 86,
      "outputs": []
    }
  ]
}